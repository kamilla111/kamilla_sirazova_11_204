# Веб-краулер + обработка текста

**Студент:** Сиразова Камилла Ирековна  
**Группа:** 11-204

## Структура проекта
- `crawler.py` — скачивание страниц
- `process.py` — токенизация и лемматизация (2-е задание)
- `urls.txt` — список URL
- `pages/` — скачанные HTML
- `tokens/` — токены **по каждой странице**
- `lemmas/` — леммы **по каждой странице**
- `tokens.txt` — **общий список токенов** 
- `lemmas.txt` — **группировка по леммам** 
- `index.txt` — индекс

## Выполнение задания

### Задание 1 (Краулер)
- 128 страниц на русском языке
- Обработка ошибок, создание `index.txt`

### Задание 2 (Токенизация + Лемматизация)
- Каждой странице соответствует свой файл токенов и лемм
- Использован **pymorphy2** — настоящая лемматизация (а не простой стемминг)
- Фильтрация: стоп-слова, короткие слова, мусор, слова с цифрами
- Созданы общие файлы `tokens.txt` и `lemmas.txt` точно в формате преподавателя

